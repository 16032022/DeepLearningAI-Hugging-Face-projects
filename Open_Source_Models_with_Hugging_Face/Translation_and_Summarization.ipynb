{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6685771",
   "metadata": {},
   "source": [
    "# Translation and Summarization ðŸŽ¯ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd303ad9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to use the Hugging Face Transformers library for translation and summarization tasks. We will go through the steps of setting up the environment, preparing the data, building the pipelines, and evaluating the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff2fb1",
   "metadata": {},
   "source": [
    "### Install and update the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02c5dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (2.5.1+cpu)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "782af222-1bea-449a-8dd4-655ad7a7b8ea",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Suppress warning messages such as non-critical log messages\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9449fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632140b",
   "metadata": {},
   "source": [
    "### Library Descriptions\n",
    "Here is a brief description of the required libraries:\n",
    "\n",
    "- The transformers library by Hugging Face provides state-of-the-art pre-trained models for natural language processing (NLP) tasks such as text classification, translation, summarization, and more. It offers easy-to-use APIs to leverage models like BERT, GPT, T5, and others.\n",
    "\n",
    "- PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab. It provides flexibility and speed for building, training, and deploying deep learning models. PyTorch is widely used for research and production due to its dynamic computational graph and strong support for GPU acceleration.\n",
    "\n",
    "- The textwrap library in Python provides utilities for formatting and wrapping plain text. It helps in breaking long strings into lines of a specified width, making the text more readable. This is particularly useful for generating neatly formatted text outputs, such as word-wrapping paragraphs in console applications or formatting text for display in a fixed-width area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea43ec1",
   "metadata": {},
   "source": [
    "### Build the `translation` pipeline using ðŸ¤— Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87460089",
   "metadata": {},
   "source": [
    "Build and train the translation pipeline using the Transformers library.\n",
    "\n",
    "### Load Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5088af",
   "metadata": {},
   "source": [
    "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ad4b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Load the translation pipeline using the NLLB model\n",
    "translator = pipeline(task=\"translation\", \n",
    "                      model=\"facebook/nllb-200-distilled-600M\", \n",
    "                      torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbf879",
   "metadata": {},
   "source": [
    "### Translation Examples\n",
    "Perform translation on example texts.\n",
    "\n",
    " - Example 1: Translation from English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095bd1c5-a96f-4b20-8e9c-601b0b158fd8",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75575792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My puppy is adorable, Your kitten is cute.\n",
      "Her panda is friendly.\n",
      "His llama is thoughtful. We all have nice pets!\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28447cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the input text from English to French\n",
    "text_translated = translator(text,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"fra_Latn\")\n",
    "\n",
    "# Uncomment the following line to print the text_translated\n",
    "#text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc03d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of the given text is:\n",
      "Mon chiot est adorable, ton chaton est mignon, son\n",
      "panda est ami, sa lamme est attentive, nous avons\n",
      "tous de beaux animaux de compagnie.\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the translation text\n",
    "translation_text = text_translated[0]['translation_text']\n",
    "wrapped_text = textwrap.fill(translation_text, width=50)\n",
    "print(f\"The translation of the given text is:\\n{wrapped_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ab814",
   "metadata": {},
   "source": [
    "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2307748",
   "metadata": {},
   "source": [
    "- Example 2: Translation from English to Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f6e3e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What are you doing today?\n",
      "\n",
      "The translation of the given text is:\n",
      "Wat doe je vandaag?\n"
     ]
    }
   ],
   "source": [
    "# Define the input text\n",
    "text1 = \"\"\"\n",
    "What are you doing today?\n",
    "\"\"\"\n",
    "print(text1)\n",
    "\n",
    "# Translate the input text from English to Dutch\n",
    "text_translated1 = translator(text1, src_lang=\"eng_Latn\", tgt_lang=\"nld_Latn\")  # Dutch\n",
    "\n",
    "# Uncomment the following line to print the text_translated\n",
    "#text_translated1\n",
    "\n",
    "# Extract and print the translation text\n",
    "translation_text = text_translated1[0]['translation_text']\n",
    "wrapped_text = textwrap.fill(translation_text, width=50)\n",
    "print(f\"The translation of the given text is:\\n{wrapped_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7517649",
   "metadata": {},
   "source": [
    "## Free up some memory before continuing\n",
    "\n",
    "Free up memory before continuing with the summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "247ca761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Delete the translator model and free up memory\n",
    "del translator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fac55f",
   "metadata": {},
   "source": [
    "### Build the `summarization` pipeline using ðŸ¤— Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca7415",
   "metadata": {},
   "source": [
    "Summarization Pipeline\n",
    "Build and train the summarization pipeline using the Transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6f847",
   "metadata": {},
   "source": [
    "Model info: ['bart-large-cnn'](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab73a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the summarization pipeline using the BART model\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee91b8",
   "metadata": {},
   "source": [
    "### Summarization Examples\n",
    "Perform summarization on example texts.\n",
    "\n",
    " - Example 1: Summarization of a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98276d66-4274-4a2f-b6a7-b4fb839b94f7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of ÃŽle-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d856f193-cbf7-450b-8ae3-42287096e56f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Summarize the input text\n",
    "summary = summarizer(text,\n",
    "                     min_length=10,\n",
    "                     max_length=100)\n",
    "\n",
    "# Uncomment the following line to print the summary\n",
    "#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ebb0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Paris is the capital and most populous city of\n",
      "France, with an estimated population of 2,175,601\n",
      "residents as of 2018. The City of Paris is the\n",
      "centre and seat of the government of the region\n",
      "and province of ÃŽle-de-France.\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the summary text\n",
    "summary_text = summary[0]['summary_text']\n",
    "wrapped_text = textwrap.fill(summary_text, width=50)\n",
    "print(f\"Summary:\\n{wrapped_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b520ba",
   "metadata": {},
   "source": [
    "- Example 2: Summarization of a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "002c0464-7d37-4b50-b3fe-4099101e2c8b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "text2 = \"\"\"Amsterdam, the capital of the Netherlands, is known for its picturesque canals,\n",
    "        historic architecture, and vibrant cultural scene. Founded in the 12th century as \n",
    "        a small fishing village, it grew into a major global trading hub during the Dutch Golden \n",
    "        Age. Today, Amsterdam is a cosmopolitan city, famous for its rich artistic heritage, \n",
    "        with museums like the Van Gogh Museum and Rijksmuseum. The city is also known for its \n",
    "        liberal attitudes, such as tolerance of cannabis use and legal sex work, as well \n",
    "        as its cycling culture, eco-friendly initiatives, and diverse, international population.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5e67790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Amsterdam, the capital of the Netherlands, is\n",
      "known for its picturesque canals, historic\n",
      "architecture, and vibrant cultural scene. Founded\n",
      "in the 12th century as a small fishing village, it\n",
      "grew into a major global trading hub. Today,\n",
      "Amsterdam is a cosmopolitan city, famous for its\n",
      "rich artistic heritage, with museums like the Van\n",
      "Gogh Museum and Rijksmuseum.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the input text\n",
    "summary2 = summarizer(text2,\n",
    "                     min_length=10,\n",
    "                     max_length=100)\n",
    "\n",
    "# Uncomment the following line to print the summary2\n",
    "#summary2\n",
    "\n",
    "# Extract and print the summary text\n",
    "summary_text = summary2[0]['summary_text']\n",
    "wrapped_text = textwrap.fill(summary_text, width=50)\n",
    "print(f\"Summary:\\n{wrapped_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9aaa3",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- The NLLB (No Language Left Behind) model offers significant benefits for translation tasks but comes with notable challenges. Advantages: It supports diverse low-resource languages, ensuring inclusivity. Its high-quality translations preserve semantic integrity, and being open-source makes it accessible and customizable. It is scalable for multilingual tasks and promotes ethical practices by aiding underrepresented communities.  Disadvantages: The model is computationally intensive and complex to fine-tune. It may carry biases from training data and struggle with underrepresented languages' quality. Latency issues arise in real-time use, and limited documentation hampers development. Evaluating its quality across languages is difficult due to the lack of benchmarks. This overview balances its inclusivity and technical strengths against operational and resource-related constraints.\n",
    "Use Case Recommendations : Best suited for projects requiring translation for low-resource or minority languages (e.g.: applications in research, social good, and cultural preservation).Less suited for scenarios requiring low latency and high scalability without robust infrastructure such as domains where hyper-specialized translation quality (e.g., medical or legal texts).\n",
    "\n",
    "- The BART (Bidirectional and Auto-Regressive Transformers) model is highly effective for abstractive summarization and other NLP tasks. It delivers high-quality, flexible, and customizable results, supported by an active community and state-of-the-art performance. However, its computational demands, susceptibility to hallucination, and challenges with domain-specific applications and poorly structured inputs pose limitations. Additionally, controlling output length and handling latency in real-time scenarios may require extra effort or resources.\n",
    "Use Case Recommendations : Best suited for: Abstractive summarization tasks where a human-like and semantically rich summary is required. Use cases involving moderately well-structured input, such as news articles, reports, and research papers.Applications with access to sufficient computational resources for efficient execution.\n",
    "Less suited for: Tasks demanding strict factual accuracy or summaries with no deviation from the original text. Scenarios where input is unstructured or noisy (e.g., raw user comments or fragmented notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91b1af",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This notebook demonstrated how to use the Hugging Face Transformers library for translation and summarization tasks. We went through the steps of setting up the environment, preparing the data, building the pipelines, and evaluating the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4a0ba",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "- Try this model with your own texts!\n",
    "- Experiment with different models and parameters.\n",
    "- Improve the performance by fine-tuning the models on specific datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2254e",
   "metadata": {},
   "source": [
    "### References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
