{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a0187c",
   "metadata": {},
   "source": [
    "# Lesson 5: Zero-Shot Audio Classification ðŸŽ§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adf368",
   "metadata": {},
   "source": [
    "- If you are running this code on your own machine, please install the following:\n",
    "``` \n",
    "    !pip install transformers\n",
    "    !pip install datasets\n",
    "    !pip install soundfile\n",
    "    !pip install librosa\n",
    "```\n",
    "\n",
    "- The trasformers library is need to use the pipeline API (available on the Hugging Face website).\n",
    "\n",
    "- Using a dataset of audio recordings in Hugging Face typically involves working with the datasets library and the Hugging Face model hub, which provides access to numerous pre-trained models that can be used for tasks like speech recognition, sound classification, or speaker identification. Hugging Face also offers tools to preprocess audio data and easily use models for inference. \n",
    "\n",
    "- Librosa is a Python library used for analyzing and processing audio files. It is widely used in music and audio signal processing tasks due to its simple interface and rich functionality. \n",
    "The `librosa` library may need to have [ffmpeg](https://www.ffmpeg.org/download.html) installed. This page on [librosa](https://pypi.org/project/librosa/) provides installation instructions for ffmpeg.\n",
    "\n",
    "- The soundfile library is a simple and efficient Python library for reading and writing sound files (audio files). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8ac3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install soundfile\n",
    "%pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a19033-a44c-48c0-b627-6f31512bbf32",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b641dcda-9522-4dbc-b9b9-388c5a061748",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "#to suppress non- critical log messages\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a28d3",
   "metadata": {},
   "source": [
    "### Prepare the dataset of audio recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9bdf6",
   "metadata": {},
   "source": [
    "- To get an overview of the audio files in a dataset using Hugging Face's datasets library, you can load the dataset and inspect the features of the dataset. When dealing with audio datasets, the audio files are typically stored in an \"audio\" column, and you can examine the dataset to get an idea of its structure and metadata.\n",
    "Use load_dataset to load the dataset you are interested in.\n",
    "In Hugging Face's datasets library, the term split refers to different subsets of the dataset that are used for various stages of model training, evaluation, and testing. A dataset is typically divided into several splits, with the most common ones being Training Split (train), which is the largest subset of the dataset and is used to train the model. The model learns from this data during training, adjusting its weights and parameters to minimize error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dc25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset, load_from_disk\n",
    "from datasets import load_dataset  #load the dataset of interest\n",
    "\n",
    "# This dataset is a collection of different sounds of 5 seconds\n",
    "dataset = load_dataset(\"ashraq/esc50\",\n",
    "                     split=\"train[0:10]\")\n",
    "#dataset = load_from_disk(\"./models/ashraq/esc50/train\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8029ec",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/ashraq/esc50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171ffb3",
   "metadata": {},
   "source": [
    "- EXAMPLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afa364c-3ef9-4528-aa80-2ee61f96df55",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3175cab3-61b5-41dd-bf0d-843322e79ffe",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afeafff-182b-4fe4-9ab6-4f3a3acc80a0",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(audio_sample[\"audio\"][\"array\"],\n",
    "             rate=audio_sample[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ed318",
   "metadata": {},
   "source": [
    "### Build the `audio classification` pipeline using ðŸ¤— Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ff9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17699d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classifier = pipeline(\n",
    "    task=\"zero-shot-audio-classification\",\n",
    "    model=\"laion/clap-htsat-unfused\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02a6f0",
   "metadata": {},
   "source": [
    "More info on [laion/clap-htsat-unfused](https://huggingface.co/laion/clap-htsat-unfused)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea87bb3-6500-4558-9fee-a20bc557f753",
   "metadata": {},
   "source": [
    "### Sampling Rate for Transformer Models\n",
    "- How long does 1 second of high resolution audio (192,000 Hz) appear to the Whisper model (which is trained to expect audio files at 16,000 Hz)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c904ec-2b9a-424b-bf1d-baad182d4b52",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "(1 * 192000) / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a1cdb-e824-4d93-a846-58e13f6756c5",
   "metadata": {},
   "source": [
    "- The 1 second of high resolution audio appears to the model as if it is 12 seconds of audio.\n",
    "\n",
    "- How about 5 seconds of audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa97b744-6a6a-49b9-ae26-ba0ff259c0d8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "(5 * 192000) / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cb81b-79c3-4852-a8d6-e8e38f6a6b9b",
   "metadata": {},
   "source": [
    "- 5 seconds of high resolution audio appears to the model as if it is 60 seconds of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da863a69-37f0-4719-9914-d49d3b25c445",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier.feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1574ba2-b1e3-4905-8f6d-7efaac7b5196",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample[\"audio\"][\"sampling_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8ea7e",
   "metadata": {},
   "source": [
    "* Set the correct sampling rate for the input and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c53b982",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0162d7-bc3f-4de9-816d-23531df64640",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\n",
    "    \"audio\",\n",
    "     Audio(sampling_rate=48_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfb2c5b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9991d3-2cc6-4289-ad51-3e6a3cf8860b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159ad36e-6c2b-4ec5-bf52-11d28f2654e4",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "candidate_labels = [\"Sound of a dog\",\n",
    "                    \"Sound of vacuum cleaner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "690a7e3f-55f2-4a09-b73b-b5a03d393e63",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier(audio_sample[\"audio\"][\"array\"],\n",
    "                     candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87adbd5c",
   "metadata": {},
   "source": [
    "From the analysis of the values of the scores, it can be concluded that the best candidate_labels seems to be \"Sound of a dog\", since its score is higher than the other candidate_labels (score 0.99 vs. 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e373d97e-c03d-4a5d-9ca5-061f82dbacc6",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "candidate_labels = [\"Sound of a child crying\",\n",
    "                    \"Sound of vacuum cleaner\",\n",
    "                    \"Sound of a bird singing\",\n",
    "                    \"Sound of an airplane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a04c213-7ab0-42b6-966b-c83c89e81b2d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier(audio_sample[\"audio\"][\"array\"],\n",
    "                     candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fc5c0",
   "metadata": {},
   "source": [
    "Following analysis of the output, it can be concluded that in above example, the highest score (0.61) seems to be related to the sound of a bird singing. Important to be mentioned that in the above list of caandidates labels the \"correct label\"(Sound of a dog) is not enclosed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8732ce4",
   "metadata": {},
   "source": [
    "- EXAMPLE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd9eb0",
   "metadata": {},
   "source": [
    "Let's try the above models with some other audio files. \n",
    "The audio files are available in the following link \n",
    "https://huggingface.co/datasets/ashraq/esc50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d3907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample1 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b807f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4307e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(audio_sample1[\"audio\"][\"array\"],\n",
    "             rate=audio_sample1[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6b91fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "zero_shot_classifier = pipeline(\n",
    "    task=\"zero-shot-audio-classification\",\n",
    "    model=\"laion/clap-htsat-unfused\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ddb74e",
   "metadata": {},
   "source": [
    " * Set the correct sampling rate for the input and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5225dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e5a29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\n",
    "    \"audio\",\n",
    "     Audio(sampling_rate=48_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ff9db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample1 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8410f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f370a",
   "metadata": {},
   "source": [
    "From the analysis of the values of the scores, it can be concluded that the best candidate_labels seems to be \"Sound of a bird\", since its score is higher than the other candidate_labels (score 0.99 vs. 0.000006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c6137c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels2 = [\"Sound of a child crying\",\n",
    "                    \"Sound of vacuum cleaner\",\n",
    "                    \"Sound of a dog\",\n",
    "                    \"Sound of an airplane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aba15fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classifier(audio_sample1[\"audio\"][\"array\"],\n",
    "                     candidate_labels=candidate_labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b87d8",
   "metadata": {},
   "source": [
    "From the analysis of the values of the scores, it can be concluded that the best candidate_labels seems to be \"Sound of a bird\", since its score (score = 0.99) is higher than the others candidate_labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ca927",
   "metadata": {},
   "source": [
    "### Try it yourself! \n",
    "- Try this model with some other labels and audio files!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
