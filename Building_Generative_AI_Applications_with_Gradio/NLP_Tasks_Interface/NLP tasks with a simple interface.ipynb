{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {},
   "source": [
    "# NLP tasks with a simple interface ✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cdfd92",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to perform various Natural Language Processing (NLP) tasks using different models from Hugging Face, integrated with Gradio for creating simple web interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6f925",
   "metadata": {},
   "source": [
    "## Load Environment Variables and Libraries\n",
    "In this section, we load the necessary environment variables and import the required libraries for our NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b1c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv #Python-dotenv is a library to load environment variables from a .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39697037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (4.7.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.5.2 (from gradio)\n",
      "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (2.2.0)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (11.0.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/codespace/.local/lib/python3.12/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from gradio-client==1.5.2->gradio) (2024.2.0)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.2->gradio)\n",
      "  Downloading websockets-14.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading orjson-3.10.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading websockets-14.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, tqdm, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, mdurl, markupsafe, ffmpy, click, annotated-types, aiofiles, uvicorn, starlette, pydantic, markdown-it-py, huggingface-hub, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 click-8.1.8 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 huggingface-hub-0.27.0 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 orjson-3.10.13 pydantic-2.10.4 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 rich-13.9.4 ruff-0.8.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.3 tomlkit-0.13.2 tqdm-4.67.1 typer-0.15.1 uvicorn-0.34.0 websockets-14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666388d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF API Key: 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\n",
      "Endpoint URL: https://api-inference.huggingface.co/models/facebook/bart-large-cnn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "hf_api_key = os.getenv('HF_API_KEY')\n",
    "#hf_api_key = os.environ['HF_API_KEY']\n",
    "endpoint_url = os.getenv('HF_API_SUMMARY_BASE')\n",
    "#ENDPOINT_URL=os.environ['HF_API_SUMMARY_BASE']\n",
    "\n",
    "# Uncomment the following line to print HF API Key and Endpoint URL\n",
    "print(\"HF API Key:\", hf_api_key)\n",
    "print(\"Endpoint URL:\", endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c8618",
   "metadata": {},
   "source": [
    "## Helper Function for Summarization\n",
    "We'll define a helper function to interact with the Hugging Face API for text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3555a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None, endpoint_url=None):\n",
    "    if not endpoint_url:\n",
    "        endpoint_url = os.getenv('HF_API_SUMMARY_BASE')\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\"inputs\": inputs}\n",
    "    if parameters:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dba1a0",
   "metadata": {},
   "source": [
    "### Running the Summarization Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d2e00",
   "metadata": {},
   "source": [
    "If you prefer to run the summarization locally, you can use the Transformers library.\n",
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a06f9",
   "metadata": {},
   "source": [
    "## Building a text summarization app\n",
    "We'll create a simple text summarization app using Gradio.\n",
    "\n",
    "- Example 1 Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. It is the second tallest free-standing structure in France after the Millau Viaduct.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02d79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary of the given text is:\n",
      "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey\n",
      "building. Its base is square, measuring 125 metres (410 ft) on each side. It is\n",
      "the second tallest free-standing structure in France after the Millau Viaduct.\n"
     ]
    }
   ],
   "source": [
    "output = get_completion(text)\n",
    "# Extract and print the summary text\n",
    "if output and 'summary_text' in output[0]:\n",
    "    summary = output[0]['summary_text']\n",
    "    formatted_text = textwrap.fill(summary, width=80)\n",
    "    # Uncomment the following line to print the formatted_text\n",
    "    #print(formatted_text)\n",
    "    print(f\"The summary of the given text is:\\n{formatted_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae782d3",
   "metadata": {},
   "source": [
    "## Creating the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://190761eae4f2846584.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://190761eae4f2846584.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)], \n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)], \n",
    "                    title=\"Text Summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\")\n",
    "demo.launch(share=True, server_port=int(os.getenv('PORT1', 7860)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28e35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef609f6",
   "metadata": {},
   "source": [
    "## Building a Named Entity Recognition App\n",
    "We are using this Inference Endpoint for dslim/bert-base-NER, a 108M parameter fine-tuned BERT model on the NER task.\n",
    "\n",
    "- Running NER Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d1d3a",
   "metadata": {},
   "source": [
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1043f",
   "metadata": {},
   "source": [
    "We are using this [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER`, a 108M parameter fine-tuned BART model on the NER task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652eb8b",
   "metadata": {},
   "source": [
    "- Example NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b696569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.8131653666496277, 'word': 'Michela', 'start': 11, 'end': 18}, {'entity_group': 'ORG', 'score': 0.9298146963119507, 'word': 'DeepLearningA', 'start': 38, 'end': 51}, {'entity_group': 'LOC', 'score': 0.9996592998504639, 'word': 'Italy', 'start': 67, 'end': 72}]\n"
     ]
    }
   ],
   "source": [
    "API_URL = os.getenv('HF_API_NER_BASE')\n",
    "text = \"My name is Michela, I'm learning from DeepLearningAI and I live in Italy\"\n",
    "output = get_completion(text, parameters=None, endpoint_url=API_URL)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b527c",
   "metadata": {},
   "source": [
    "## Creating the Gradio Interface for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cf6339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/gradio/interface.py:399: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* Running on public URL: https://3f32dc6402b1b332fe.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3f32dc6402b1b332fe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, endpoint_url=API_URL)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Michela and I live in Italy\", \"My name is Andrew and work at HuggingFace\"])\n",
    "demo.launch(share=True, server_port=int(os.getenv('PORT2', 7870)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109b6ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {},
   "source": [
    "### Adding a helper function to merge tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a801c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/gradio/interface.py:399: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* Running on public URL: https://199c0bb68dc1f208a1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://199c0bb68dc1f208a1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mock function simulating an API response\n",
    "def get_completion(input, parameters=None, ENDPOINT_URL=None):\n",
    "    # Simulating tokens, some of which might be missing the 'entity' key\n",
    "    return [\n",
    "        {\"word\": \"My\", \"start\": 0, \"end\": 2, \"score\": 0.95, \"entity\": \"B-PER\"},\n",
    "        {\"word\": \"name\", \"start\": 3, \"end\": 7, \"score\": 0.98, \"entity\": \"I-PER\"},\n",
    "        {\"word\": \"is\", \"start\": 8, \"end\": 10, \"score\": 0.90},\n",
    "        {\"word\": \"Andrew\", \"start\": 11, \"end\": 17, \"score\": 0.99, \"entity\": \"I-PER\"},\n",
    "        {\"word\": \"and\", \"start\": 18, \"end\": 21, \"score\": 0.88},\n",
    "        {\"word\": \"I\", \"start\": 22, \"end\": 23, \"score\": 0.93, \"entity\": \"B-PER\"},\n",
    "        {\"word\": \"live\", \"start\": 24, \"end\": 28, \"score\": 0.97, \"entity\": \"O\"},\n",
    "        {\"word\": \"in\", \"start\": 29, \"end\": 31, \"score\": 0.89, \"entity\": \"O\"},\n",
    "        {\"word\": \"California\", \"start\": 32, \"end\": 42, \"score\": 0.96, \"entity\": \"B-LOC\"},\n",
    "    ]\n",
    "\n",
    "# Updated function to merge tokens (Helper function)\n",
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if 'entity' not in token:\n",
    "            continue  # Skip tokens without 'entity'\n",
    "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            merged_tokens.append(token)\n",
    "    return merged_tokens\n",
    "\n",
    "# Main NER function\n",
    "def ner(input):\n",
    "    try:\n",
    "        output = get_completion(input, parameters=None, ENDPOINT_URL=None)\n",
    "        merged_tokens = merge_tokens(output)\n",
    "        return {\"text\": input, \"entities\": merged_tokens}\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"text\": input, \"entities\": []}\n",
    "\n",
    "# Gradio Interface\n",
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "    title=\"NER with dslim/bert-base-NER\",\n",
    "    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "    allow_flagging=\"never\",\n",
    "    examples=[\n",
    "        \"My name is Andrew, I'm building DeeplearningAI and I live in California\",\n",
    "        \"My name is Michela, I live in Italy and learn from HuggingFace\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(share=True, server_port=int(os.environ.get('PORT4', 7860)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7890\n",
      "Closing server running on port: 7880\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1775a8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we demonstrated how to perform text summarization and named entity recognition using models from Hugging Face. We also showed how to create interactive web interfaces using Gradio. For more advanced applications, consider exploring additional models and features provided by Hugging Face and Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5a409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
