{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88535ead",
   "metadata": {},
   "source": [
    "# NLP tasks with a simple interface âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cdfd92",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to perform various Natural Language Processing (NLP) tasks using different models from Hugging Face, integrated with Gradio for creating simple web interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6f925",
   "metadata": {},
   "source": [
    "### Install and Import Libraries\n",
    "Here is a brief description of the required libraries:\n",
    "- The python-dotenv library is used to load environment variables from a .env file into your application's environment. It helps manage sensitive configuration details like API keys and database credentials.\n",
    "\n",
    "- The Gradio library is a library for building user-friendly web-based interfaces for machine learning models and data pipelines. It allows you to create interactive demos with minimal code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b1c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Install and update the necessary libraries\n",
    "%pip install python-dotenv \n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e5c31",
   "metadata": {},
   "source": [
    "- Loading API Keys and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666388d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF API Key: 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\n",
      "Endpoint URL: https://api-inference.huggingface.co/models/facebook/bart-large-cnn\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import os  # os provides a way of using operating system-dependent functionality\n",
    "import io  # this library provides core tools for working with streams of data\n",
    "from IPython.display import Image, display, HTML  # This is used for displaying rich content (e.g., images, HTML) in Jupyter Notebooks\n",
    "from PIL import Image  # Python Imaging Library (PIL) is used for opening, manipulating, and saving image files\n",
    "import base64   # This library encodes and decodes data in base64 format\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import gradio as gr\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "hf_api_key = os.getenv('HF_API_KEY')\n",
    "endpoint_url = os.getenv('HF_API_SUMMARY_BASE')\n",
    "\n",
    "# Uncomment the following line to print HF API Key and Endpoint URL\n",
    "#print(\"HF API Key:\", hf_api_key)\n",
    "#print(\"Endpoint URL:\", endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c8618",
   "metadata": {},
   "source": [
    "### Helper Function for Summarization\n",
    "We'll define a helper function to interact with the Hugging Face API for text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3555a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Send API Requests for Text Completion with Error Handling\n",
    "def get_completion(inputs, parameters=None, endpoint_url=None):\n",
    "    if not endpoint_url:\n",
    "        endpoint_url = os.getenv('HF_API_SUMMARY_BASE')\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\"inputs\": inputs}\n",
    "    if parameters:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    try:\n",
    "        response = requests.post(endpoint_url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dba1a0",
   "metadata": {},
   "source": [
    "**Note** Running the Summarization Locally. If you prefer to run the summarization locally, you can use the Transformers library.\n",
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a06f9",
   "metadata": {},
   "source": [
    "## Building a text summarization app\n",
    "We'll create a simple text summarization app using Gradio.\n",
    "\n",
    "- Example 1 Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f0fc58-91d6-48f2-a014-052192586be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. It is the second tallest free-standing structure in France after the Millau Viaduct.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02d79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary of the given text is:\n",
      "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey\n",
      "building. Its base is square, measuring 125 metres (410 ft) on each side. It is\n",
      "the second tallest free-standing structure in France after the Millau Viaduct.\n"
     ]
    }
   ],
   "source": [
    "output = get_completion(text)\n",
    "# Extract and print the summary text\n",
    "if output and 'summary_text' in output[0]:\n",
    "    summary = output[0]['summary_text']\n",
    "    formatted_text = textwrap.fill(summary, width=80)\n",
    "    # Uncomment the following line to print the formatted_text\n",
    "    #print(formatted_text)\n",
    "    print(f\"The summary of the given text is:\\n{formatted_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae782d3",
   "metadata": {},
   "source": [
    "## Creating the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://190761eae4f2846584.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://190761eae4f2846584.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)], \n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)], \n",
    "                    title=\"Text Summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\")\n",
    "demo.launch(share=True, server_port=int(os.getenv('PORT1', 7860)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28e35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Close the demo\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef609f6",
   "metadata": {},
   "source": [
    "## Building a Named Entity Recognition App\n",
    "**Note** As Interface Endpoint has been used the [Inference Endpoint](https://huggingface.co/inference-endpoints) for `dslim/bert-base-NER` (HF_API_NER_BASE), a 108M parameter fine-tuned BERT model on the NER task.\n",
    "\n",
    "**Note** Running the NER Locally. If you prefer to run the summarization locally, you can use the Transformers library.\n",
    "```py\n",
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652eb8b",
   "metadata": {},
   "source": [
    "- Performing Named Entity Recognition (NER) Using an API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e46af3",
   "metadata": {},
   "source": [
    " Briefly, the below code sends a text string to a NER API endpoint, retrieves the processed output, and prints it. It utilizes the get_completion function to handle the API request, where the endpoint URL is sourced from an environment variable (HF_API_NER_BASE). The provided text contains personal information to extract entities like names, affiliations, and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b696569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.8131653666496277, 'word': 'Michela', 'start': 11, 'end': 18}, {'entity_group': 'ORG', 'score': 0.9298146963119507, 'word': 'DeepLearningA', 'start': 38, 'end': 51}, {'entity_group': 'LOC', 'score': 0.9996592998504639, 'word': 'Italy', 'start': 67, 'end': 72}]\n"
     ]
    }
   ],
   "source": [
    "API_URL = os.getenv('HF_API_NER_BASE')\n",
    "text = \"My name is Michela, I'm learning from DeepLearningAI and I live in Italy\"\n",
    "output = get_completion(text, parameters=None, endpoint_url=API_URL)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4480b14",
   "metadata": {},
   "source": [
    "Explanation output : The above output is the result of a Named Entity Recognition (NER) task performed on the input text. It identifies and classifies specific words or phrases as entities belonging to predefined categories. Briefy, Key Elements in the Output are Entity Groups (PER: Refers to a person, ORG: Refers to an organization, LOC: Refers to a location), Score (Indicates the confidence level of the model in classifying the entity correctly), Word (The specific word or phrase identified as an entity in the input text.) In the above output 3 Entities have been detected (Michela, DeepLearningAI, Italy, repectively for PER, ORG, LOC ) with their respective score (e.g.: The model identifies \"Michela\" as a person with 81.3% confidence, DeepLearningA\" is identified as an organization with 92.9% confidence, and \"Italy\" is identified as a location with 99.9% confidence). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b527c",
   "metadata": {},
   "source": [
    "## Creating the Gradio Interface for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cf6339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/gradio/interface.py:399: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* Running on public URL: https://3f32dc6402b1b332fe.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3f32dc6402b1b332fe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, endpoint_url=API_URL)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Michela and I live in Italy\", \"My name is Andrew and work at HuggingFace\"])\n",
    "demo.launch(share=True, server_port=int(os.getenv('PORT2', 7870)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109b6ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Close the Demo\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16ad4",
   "metadata": {},
   "source": [
    "### Adding a helper function to merge tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a801c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/gradio/interface.py:399: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* Running on public URL: https://199c0bb68dc1f208a1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://199c0bb68dc1f208a1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mock function simulating an API response\n",
    "def get_completion(input, parameters=None, ENDPOINT_URL=None):\n",
    "    # Simulating tokens, some of which might be missing the 'entity' key\n",
    "    return [\n",
    "        {\"word\": \"My\", \"start\": 0, \"end\": 2, \"score\": 0.95, \"entity\": \"B-PER\"},\n",
    "        {\"word\": \"name\", \"start\": 3, \"end\": 7, \"score\": 0.98, \"entity\": \"I-PER\"},\n",
    "        {\"word\": \"is\", \"start\": 8, \"end\": 10, \"score\": 0.90},\n",
    "        {\"word\": \"Andrew\", \"start\": 11, \"end\": 17, \"score\": 0.99, \"entity\": \"I-PER\"},\n",
    "        {\"word\": \"and\", \"start\": 18, \"end\": 21, \"score\": 0.88},\n",
    "        {\"word\": \"I\", \"start\": 22, \"end\": 23, \"score\": 0.93, \"entity\": \"B-PER\"},\n",
    "        {\"word\": \"live\", \"start\": 24, \"end\": 28, \"score\": 0.97, \"entity\": \"O\"},\n",
    "        {\"word\": \"in\", \"start\": 29, \"end\": 31, \"score\": 0.89, \"entity\": \"O\"},\n",
    "        {\"word\": \"California\", \"start\": 32, \"end\": 42, \"score\": 0.96, \"entity\": \"B-LOC\"},\n",
    "    ]\n",
    "\n",
    "# Updated function to merge tokens (Helper function)\n",
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if 'entity' not in token:\n",
    "            continue  # Skip tokens without 'entity'\n",
    "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            merged_tokens.append(token)\n",
    "    return merged_tokens\n",
    "\n",
    "# Main NER function\n",
    "def ner(input):\n",
    "    try:\n",
    "        output = get_completion(input, parameters=None, ENDPOINT_URL=None)\n",
    "        merged_tokens = merge_tokens(output)\n",
    "        return {\"text\": input, \"entities\": merged_tokens}\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"text\": input, \"entities\": []}\n",
    "\n",
    "# Gradio Interface\n",
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "    title=\"NER with dslim/bert-base-NER\",\n",
    "    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "    allow_flagging=\"never\",\n",
    "    examples=[\n",
    "        \"My name is Andrew, I'm building DeeplearningAI and I live in California\",\n",
    "        \"My name is Michela, I live in Italy and learn from HuggingFace\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch(share=True, server_port=int(os.environ.get('PORT4', 7860)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cccdb9b-0c3a-406e-95bc-106705aeb010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7890\n",
      "Closing server running on port: 7880\n"
     ]
    }
   ],
   "source": [
    "# Close the demo\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1775a8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we demonstrated how to perform text summarization and named entity recognition using models from Hugging Face. We also showed how to create interactive web interfaces using Gradio. For more advanced applications, consider exploring additional models and features provided by:\n",
    "- [Gradio Documentation](https://gradio.app)\n",
    "- [Hugging Face API](https://huggingface.co/docs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5a409",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Experiment with Different Promts: Try using other prompts!\n",
    "- Experiment with Different Models: Try using other text summarization and named entity recognition  models available on Hugging Face to see how their performance compares!\n",
    "- Deploy the App: Deploy your Gradio app to Hugging Face Spaces to make it accessible to others!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
